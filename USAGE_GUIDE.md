# Alloyæ¤œè¨¼æ¸ˆã¿Kaggleå®Ÿè£… - ä½¿ç”¨ã‚¬ã‚¤ãƒ‰

**å®Ÿè£…ãƒ•ã‚¡ã‚¤ãƒ«**: `kaggle_alloy_implementation.py`  
**Alloyãƒ¢ãƒ‡ãƒ«**: `kaggle_competition_v3_final.als`  
**æ¤œè¨¼æ¸ˆã¿ã‚´ãƒ¼ãƒ«**: âœ… G1, âœ… G2, âœ… G3ï¼ˆG4ã¯å®Ÿè£…ãƒ¬ãƒ™ãƒ«ï¼‰

---

## ğŸ¯ ã“ã®ã‚¬ã‚¤ãƒ‰ã«ã¤ã„ã¦

ã“ã®Pythonå®Ÿè£…ã¯ã€Alloyå½¢å¼æ‰‹æ³•ã§æ¤œè¨¼æ¸ˆã¿ã®åˆ¶ç´„ã‚’æº€ãŸã™Kaggleãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã§ã™ã€‚
**G1-G3ãŒAlloyæ¤œè¨¼æ¸ˆã¿**ã€G4ã¯å®Ÿè£…ãƒ¬ãƒ™ãƒ«ã§è¿½åŠ ã•ã‚Œã¦ã„ã¾ã™ã€‚

---

## ğŸš€ ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ

### 1. ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã§å®Ÿè¡Œ

```bash
python kaggle_alloy_implementation.py
```

**å®Ÿè¡Œçµæœ**ï¼š
```
âœ… [G1] ãƒ‡ãƒ¼ã‚¿å“è³ªä¿è¨¼ï¼ˆAlloyæ¤œè¨¼æ¸ˆã¿ï¼‰
âœ… [G2] ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ï¼ˆAlloyæ¤œè¨¼æ¸ˆã¿ï¼‰
âœ… [G3] ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰ï¼ˆAlloyæ¤œè¨¼æ¸ˆã¿ï¼‰
âœ… PracticalKagglePipelineé”æˆ
```

---

## ğŸ“Š å®Ÿéš›ã®Kaggleãƒ‡ãƒ¼ã‚¿ã§å®Ÿè¡Œ

### ã‚¹ãƒ†ãƒƒãƒ—1: ã‚¿ã‚¤ã‚¿ãƒ‹ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰

```bash
# Kaggle CLIã‚’ä½¿ç”¨
kaggle competitions download -c titanic
unzip titanic.zip
```

### ã‚¹ãƒ†ãƒƒãƒ—2: ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ä½œæˆ

`run_titanic.py`ã‚’ä½œæˆï¼š

```python
"""
ã‚¿ã‚¤ã‚¿ãƒ‹ãƒƒã‚¯ã‚³ãƒ³ãƒšå®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""
import pandas as pd
from kaggle_alloy_implementation import KagglePipeline

def main():
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    train_df = pd.read_csv('train.csv')
    test_df = pd.read_csv('test.csv')
    
    print(f"è¨“ç·´ãƒ‡ãƒ¼ã‚¿: {len(train_df)}è¡Œ")
    print(f"ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {len(test_df)}è¡Œ")
    
    # ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ
    pipeline = KagglePipeline()
    predictions, results = pipeline.execute(train_df, test_df)
    
    # æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
    submission = pd.DataFrame({
        'PassengerId': test_df['PassengerId'],
        'Survived': predictions
    })
    submission.to_csv('submission.csv', index=False)
    
    print("\nâœ… submission.csvä½œæˆå®Œäº†ï¼")
    print(f"è¨“ç·´ç²¾åº¦: {results['train_metrics']['accuracy']:.4f}")
    print(f"CVç²¾åº¦: {results['cv_results']['cv_mean']:.4f}")
    
    return submission, results

if __name__ == '__main__':
    submission, results = main()
```

### ã‚¹ãƒ†ãƒƒãƒ—3: å®Ÿè¡Œ

```bash
python run_titanic.py
```

### ã‚¹ãƒ†ãƒƒãƒ—4: Kaggleã«æå‡º

```bash
kaggle competitions submit -c titanic -f submission.csv -m "Alloyæ¤œè¨¼æ¸ˆã¿ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³"
```

---

## ğŸ”§ Alloyåˆ¶ç´„ã¨ã®å¯¾å¿œ

### G1: ãƒ‡ãƒ¼ã‚¿å“è³ªä¿è¨¼

| Python | Alloyåˆ¶ç´„ | èª¬æ˜ |
|--------|----------|------|
| `handle_missing_values()` | `fact MissingValueHandling` | æ¬ æå€¤å‡¦ç† |
| `handle_outliers()` | `fact OutlierConstraints` | å¤–ã‚Œå€¤å‡¦ç†ï¼ˆå¹´é½¢0-120ï¼‰ |
| `validate_no_missing()` | `assert NoMissingAfterProcessing` | å‰å‡¦ç†å¾Œã®æ¬ æå€¤ãªã— |
| `validate_train_test_separation()` | `fact TrainTestSeparation` | è¨“ç·´ãƒ»ãƒ†ã‚¹ãƒˆåˆ†é›¢ |

### G2: ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°

| Python | Alloyåˆ¶ç´„ | èª¬æ˜ |
|--------|----------|------|
| `create_features()` | `fact FeatureEngineeringRules` | æ–°ç‰¹å¾´é‡ç”Ÿæˆ |
| `validate_new_features_exist()` | `some fed.newFeatures` | æ–°ç‰¹å¾´é‡ãŒå­˜åœ¨ |

ç”Ÿæˆã•ã‚Œã‚‹ç‰¹å¾´é‡ï¼š
- **FamilySize**: ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜ï¼ˆSibSp + Parch + 1ï¼‰
- **IsAlone**: ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜ï¼ˆFamilySize == 1ï¼‰
- **Age_binned_numeric**: çµ±è¨ˆçš„ï¼ˆå¹´é½¢ã‚’4ã¤ã®ãƒ“ãƒ³ã«åˆ†é¡ï¼‰
- **Fare_per_person**: ç›¸äº’ä½œç”¨ï¼ˆFare / FamilySizeï¼‰

### G3: ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰

| Python | Alloyåˆ¶ç´„ | èª¬æ˜ |
|--------|----------|------|
| `set_hyperparameters()` | `fact HyperparameterConstraints` | ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç¯„å›² |
| `train()` | `some tm.model` | ãƒ¢ãƒ‡ãƒ«è¨“ç·´ |
| `predict()` | `fact PredictionBinary` | äºˆæ¸¬å€¤0/1ãƒã‚§ãƒƒã‚¯ |
| `validate_hyperparameters()` | `assert ValidHyperparameters` | ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å¦¥å½“æ€§ |

ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åˆ¶ç´„ï¼š
- `max_depth`: [1, 20]
- `n_estimators`: [1, 1000]

### G4: è©•ä¾¡ï¼ˆå®Ÿè£…ãƒ¬ãƒ™ãƒ«ã®ã¿ï¼‰

| Python | Alloyåˆ¶ç´„ | èª¬æ˜ |
|--------|----------|------|
| `evaluate()` | ãªã— | ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ |
| `cross_validate()` | ãªã— | ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ |

**æ³¨æ„**: G4ã¯Alloyã§å½¢å¼åŒ–ã—ã¦ã„ã¾ã›ã‚“ï¼ˆå½¢å¼åŒ–å›°é›£ã®ãŸã‚ï¼‰ã€‚

---

## ğŸ’¡ ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºæ–¹æ³•

### 1. æ–°ã—ã„ç‰¹å¾´é‡ã‚’è¿½åŠ 

```python
class FeatureEngineer:
    def create_features(self, df: pd.DataFrame) -> pd.DataFrame:
        df = df.copy()
        
        # æ—¢å­˜ã®ç‰¹å¾´é‡ç”Ÿæˆ...
        
        # æ–°ã—ã„ç‰¹å¾´é‡ã‚’è¿½åŠ 
        if 'Name' in df.columns:
            df['Title'] = df['Name'].str.extract(' ([A-Za-z]+)\.', expand=False)
            df['Title_encoded'] = pd.factorize(df['Title'])[0]
            self.new_features.append('Title_encoded')
            print(f"  ğŸ”§ Title_encodedç”Ÿæˆ")
        
        # Alloyåˆ¶ç´„ã¯è‡ªå‹•çš„ã«æº€ãŸã•ã‚Œã‚‹
        self.validator.validate_new_features_exist(df, self.new_features)
        
        return df
```

### 2. ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®èª¿æ•´

```python
# Alloyåˆ¶ç´„å†…ã®ç¯„å›²ã§èª¿æ•´
pipeline = KagglePipeline()

# æ–¹æ³•1: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’å¤‰æ›´
trainer = pipeline.trainer
trainer.set_hyperparameters(
    max_depth=15,      # [1, 20]ã®ç¯„å›²å†…
    n_estimators=200,  # [1, 1000]ã®ç¯„å›²å†…
    min_samples_split=10
)

# æ–¹æ³•2: run_titanic.pyå†…ã§ç›´æ¥è¨­å®š
predictions, results = pipeline.execute(train_df, test_df)
```

### 3. åˆ¥ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨

```python
from sklearn.linear_model import LogisticRegression

class ModelTrainer:
    def train(self, X, y):
        # RandomForest â†’ LogisticRegression
        self.model = LogisticRegression(**self.hyperparameters, random_state=42)
        self.model.fit(X, y)
        
        # Alloyåˆ¶ç´„ã¯è‡ªå‹•çš„ã«æº€ãŸã•ã‚Œã‚‹
        return self.model
```

---

## ğŸ› ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### ã‚¨ãƒ©ãƒ¼1: æ¬ æå€¤ãŒæ®‹ã£ã¦ã„ã‚‹

```
[G1é•å] æ¬ æå€¤å‡¦ç†å¾Œ: æ¬ æå€¤ãŒ5å€‹æ®‹ã£ã¦ã„ã¾ã™
```

**åŸå› **: æ–°ã—ã„ã‚«ãƒ©ãƒ ã®æ¬ æå€¤å‡¦ç†ãŒä¸è¶³

**è§£æ±º**:
```python
def handle_missing_values(self, df):
    df = df.copy()
    
    # æ•°å€¤ãƒ»ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å‡¦ç†...
    
    # æ–°ã—ã„ã‚«ãƒ©ãƒ ã‚’è¿½åŠ ã—ãŸå ´åˆã¯å‡¦ç†ã‚’è¿½åŠ 
    if 'NewColumn' in df.columns:
        df['NewColumn'].fillna(df['NewColumn'].median(), inplace=True)
    
    return df
```

### ã‚¨ãƒ©ãƒ¼2: ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒç¯„å›²å¤–

```
[G3é•å] max_depthã¯[1, 20]ã®ç¯„å›²: 25
```

**åŸå› **: Alloyåˆ¶ç´„é•å

**è§£æ±º**:
```python
# åˆ¶ç´„å†…ã«åã‚ã‚‹
trainer.set_hyperparameters(
    max_depth=20,  # 20ä»¥ä¸‹
    n_estimators=500  # 1000ä»¥ä¸‹
)
```

### ã‚¨ãƒ©ãƒ¼3: è¨“ç·´ãƒ»ãƒ†ã‚¹ãƒˆé‡è¤‡

```
[G1é•å] è¨“ç·´ã¨ãƒ†ã‚¹ãƒˆãŒ100è¡Œé‡è¤‡ã—ã¦ã„ã¾ã™
```

**åŸå› **: ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒé‡è¤‡

**è§£æ±º**:
```python
# ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ˜ç¤ºçš„ã«è¨­å®š
train_df = pd.DataFrame({...}, index=range(0, 100))
test_df = pd.DataFrame({...}, index=range(100, 150))
```

---

## ğŸ“ˆ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Šã®ãƒ’ãƒ³ãƒˆ

### 1. ç‰¹å¾´é‡ã®è¿½åŠ 

```python
# Nameï¼ˆæ•¬ç§°ï¼‰
df['Title'] = df['Name'].str.extract(' ([A-Za-z]+)\.', expand=False)

# Cabinï¼ˆæœ€åˆã®æ–‡å­—ï¼‰
df['Cabin_letter'] = df['Cabin'].str[0]

# Sexï¼ˆæ•°å€¤åŒ–ï¼‰
df['Sex_encoded'] = df['Sex'].map({'male': 0, 'female': 1})
```

### 2. ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°

```python
# Grid Searchï¼ˆæ‰‹å‹•ï¼‰
best_score = 0
best_params = {}

for depth in [5, 10, 15, 20]:
    for n_est in [50, 100, 200]:
        trainer.set_hyperparameters(
            max_depth=depth,
            n_estimators=n_est
        )
        model = trainer.train(X_train, y_train)
        cv_results = evaluator.cross_validate(model, X_train, y_train)
        
        if cv_results['cv_mean'] > best_score:
            best_score = cv_results['cv_mean']
            best_params = {'max_depth': depth, 'n_estimators': n_est}

print(f"æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {best_params}")
print(f"æœ€é«˜ã‚¹ã‚³ã‚¢: {best_score:.4f}")
```

### 3. ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«

```python
# è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ã‚’å¹³å‡
models = []

# ãƒ¢ãƒ‡ãƒ«1
trainer1 = ModelTrainer(validator)
trainer1.set_hyperparameters(max_depth=10, n_estimators=100)
model1 = trainer1.train(X_train, y_train)
models.append(model1)

# ãƒ¢ãƒ‡ãƒ«2
trainer2 = ModelTrainer(validator)
trainer2.set_hyperparameters(max_depth=15, n_estimators=200)
model2 = trainer2.train(X_train, y_train)
models.append(model2)

# ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬
predictions = []
for model in models:
    pred = model.predict(X_test)
    predictions.append(pred)

# å¤šæ•°æ±º
final_predictions = np.round(np.mean(predictions, axis=0)).astype(int)
```

---

## ğŸ“š Alloyãƒ¢ãƒ‡ãƒ«ã¨ã®å®Œå…¨å¯¾å¿œè¡¨

### è¿°èªï¼ˆPredicatesï¼‰

| Alloyè¿°èª | Pythonå®Ÿè£… | èª¬æ˜ |
|-----------|-----------|------|
| `G1_Achieved` | `DataPreprocessor` | ãƒ‡ãƒ¼ã‚¿å“è³ªä¿è¨¼ |
| `G2_Achieved` | `FeatureEngineer` | ç‰¹å¾´é‡ç”Ÿæˆ |
| `G3_Achieved` | `ModelTrainer` | ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰ |
| `PracticalKagglePipeline` | `KagglePipeline.execute()` | G1âˆ§G2âˆ§G3 |

### ãƒ•ã‚¡ã‚¯ãƒˆï¼ˆFactsï¼‰

| Alloy Fact | Pythonæ¤œè¨¼ | ã‚¿ã‚¤ãƒŸãƒ³ã‚° |
|-----------|-----------|----------|
| `MissingValueHandling` | `validate_no_missing()` | G1å®Œäº†æ™‚ |
| `OutlierConstraints` | `validate_outliers()` | G1å®Œäº†æ™‚ |
| `FeatureEngineeringRules` | `validate_new_features_exist()` | G2å®Œäº†æ™‚ |
| `HyperparameterConstraints` | `validate_hyperparameters()` | G3é–‹å§‹æ™‚ |
| `TrainTestSeparation` | `validate_train_test_separation()` | ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³é–‹å§‹æ™‚ |
| `PredictionBinary` | `validate_predictions_binary()` | G3äºˆæ¸¬æ™‚ |

### ã‚¢ã‚µãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆAssertionsï¼‰

| Alloy Assertion | Pythonæ¤œè¨¼ | çµæœ |
|----------------|-----------|------|
| `NoMissingAfterProcessing` | æœ€çµ‚æ¤œè¨¼ | âœ… åˆæ ¼ |
| `NoTrainTestOverlap` | é–‹å§‹æ™‚æ¤œè¨¼ | âœ… åˆæ ¼ |
| `ValidHyperparameters` | G3é–‹å§‹æ™‚æ¤œè¨¼ | âœ… åˆæ ¼ |
| `PredictionsAreBinary` | G3äºˆæ¸¬æ™‚æ¤œè¨¼ | âœ… åˆæ ¼ |

---

## ğŸ¯ å®Ÿè¡Œçµæœã®è¦‹æ–¹

### æˆåŠŸä¾‹

```
âœ… [G1] ãƒ‡ãƒ¼ã‚¿å“è³ªä¿è¨¼ï¼ˆAlloyæ¤œè¨¼æ¸ˆã¿ï¼‰
âœ… [G2] ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ï¼ˆAlloyæ¤œè¨¼æ¸ˆã¿ï¼‰
âœ… [G3] ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰ï¼ˆAlloyæ¤œè¨¼æ¸ˆã¿ï¼‰
âœ… PracticalKagglePipelineé”æˆ

è¨“ç·´ç²¾åº¦: 0.9700
CVç²¾åº¦: 0.5300
ãƒ†ã‚¹ãƒˆäºˆæ¸¬æ•°: 50
```

**è§£é‡ˆ**ï¼š
- **è¨“ç·´ç²¾åº¦**: è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã§ã®ç²¾åº¦ï¼ˆé«˜ã™ãã‚‹å ´åˆã¯éå­¦ç¿’ã®å¯èƒ½æ€§ï¼‰
- **CVç²¾åº¦**: ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ç²¾åº¦ï¼ˆæ±åŒ–æ€§èƒ½ã®ç›®å®‰ï¼‰
- **äºˆæ¸¬æ•°**: ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®è¡Œæ•°ã¨ä¸€è‡´ã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª

---

## ğŸ‰ ã¾ã¨ã‚

ã“ã®Pythonå®Ÿè£…ã¯ï¼š

âœ… **Alloyå½¢å¼æ‰‹æ³•ã§æ¤œè¨¼æ¸ˆã¿**ï¼ˆG1-G3ï¼‰  
âœ… **å®Ÿéš›ã®Kaggleã‚³ãƒ³ãƒš**ã§ä½¿ç”¨å¯èƒ½  
âœ… **æ‹¡å¼µãƒ»ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º**ãŒå®¹æ˜“  
âœ… **æ•™è‚²ãƒ»ç ”ç©¶**ã«æœ€é©  

**AI-Augmentedå½¢å¼æ‰‹æ³•ã®å®Ÿè·µä¾‹**ã¨ã—ã¦ã€ãƒ–ãƒ­ã‚°è¨˜äº‹ã‚„ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã«æœ€é©ã§ã™ï¼

---

## ğŸ“– é–¢é€£ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ

- **Alloyãƒ¢ãƒ‡ãƒ«**: `kaggle_competition_v3_final.als`
- **KAOS Goalæ§‹é€ **: `claude_code_learning_kaos.als`
- **è©³ç´°ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ**: `kaggle_ai_augmented_formal_methods.md`
- **ã‚¨ãƒ©ãƒ¼ä¿®æ­£ã‚¬ã‚¤ãƒ‰**: `alloy_error_fix_guide.md`
- **éå‰°åˆ¶ç´„åˆ†æ**: `over_constrained_analysis.md`

---

**ä½œæˆæ—¥**: 2026å¹´1æœˆ28æ—¥  
**ä½œæˆè€…**: å¤é–‘å¼˜æ™ƒ  
**ãƒ©ã‚¤ã‚»ãƒ³ã‚¹**: MIT
